{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python39064bit7fd64d56249f462394dc94080af000bd",
   "display_name": "Python 3.9.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Binary IBDM\n",
    "This notebook shows how to do image based data mining against a binary outcome. The outcome could be whatever you like, provided it is binary; some examples include overall survival, locoregional failure and feeding tube insertion.\n",
    "\n",
    "First, we will install and load a few packages we will need"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "source": [
    "We will also download the HNSCC data and unzip it\n",
    "\n",
    "# NOTE: you might not need to do this is you end up on the same runtime as in the registration example, check the file browser on the left"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/msb4uiq8rw79rqe/HNSCC_data.zip?dl=0 -O ./HNSCC_data.zip\n",
    "!unzip HNSCC_data.zip\n",
    "!rm HNSCC_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries we want and set up the notebook\n",
    "import os\n",
    "import time\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "try:\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "    haveTQDM = True\n",
    "except:\n",
    "    haveTQDM = False\n",
    "\n",
    "print(haveTQDM)\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## Make the notebook use full width of display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "source": [
    "# Getting started\n",
    "\n",
    "To do an IBDM analysis, we need a few things:\n",
    "\n",
    "- Registered data, so that the anatomy is (as far as possible) in the same spatial location\n",
    "- Some kind of outcome to mine against\n",
    "- A good understanding of any confounding variables in the dataset\n",
    "\n",
    "We will use pandas to load a csv file of the data. Pandas is very powerful - here we will be using only its most basic functions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the clinical data CSV\n",
    "clinicalDataPath = \"/content/HNSCC_data/clinicalData.csv\"\n",
    "\n",
    "clinicalData = pd.read_csv(clinicalDataPath)\n",
    "\n"
   ]
  },
  {
   "source": [
    "Head and neck cancer is one of the more complex treatments, and often has several stages including surgery, chemotherapy alone, and concurrent chemo-RT. If we were to leave this complexity unaddressed we would probably introduce some bias, or leave some confounding information unaccounted for. Before doing anything, we will attempt to standardise a sub-cohort to do our IBDM in.\n",
    "\n",
    "In the clinical data is a column recording what type of treatment a patient had. We can look at that column by indexing the dataframe with the column heading like this:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinicalData[\"Oncologic Treatment Summary\"]"
   ]
  },
  {
   "source": [
    "There are a lot of acronyms going on in this data, the most important are:\n",
    "\n",
    "CMT  = Chemotherapy\n",
    "ERT  = External beam radiotherapy\n",
    "CCRT = Concurrent Chemo-radiotherapy\n",
    "\n",
    "Other information includes what type of treatment was used when in a patient's pathway, for eaxmple:\n",
    "\n",
    "`Surgery --> CMT --> CCRT + Cetuximab`\n",
    "\n",
    "means a patient had surgery, then chemotherapy, then concurrent chemo-radiotherapy with an immunotherapy drug called Cetuximab.\n",
    "\n",
    "The type of treatment a patient recieved is very important, because it affects how they respond. To remove potential confounding effects in our image based data mining, we would like to have all the patients be on as similar a course of treatment as possible. \n",
    "\n",
    "As a first set of patients to try, lets only take patients who started their treatment with CCRT. We will allow patients who had surgery after radiotherapy, because that shouldn't affect their response to the radiation. If we were being really strict, we could also exclude these patients/place some limit on when events occurred.\n",
    "\n",
    "We can reduce our dataset using some pandas indexing tricks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrtOnlyPatients = clinicalData[(clinicalData[\"Oncologic Treatment Summary\"].str.contains('^CCRT', regex=True)) & (clinicalData[\"Oncologic Treatment Summary\"].str.contains('\\+', regex=True) == False)]\n",
    "len(ccrtOnlyPatients[\"Oncologic Treatment Summary\"])"
   ]
  },
  {
   "source": [
    "To explain what is going on here:\n",
    "\n",
    "- `[]` indexes the dataframe, getting values out of it. We can do this with a boolean mask \n",
    "- `(clinicalData[\"Oncologic Treatment Summary\"].str.contains('^CCRT', regex=True))` asks \"Does the value in this cell start with CCRT?\" It says True where this is the case\n",
    "- `(clinicalData[\"Oncologic Treatment Summary\"].str.contains('\\+', regex=True) == False)` Asks \"Does the value in this cell not contain a + symbol?\n",
    "- The `&` symbol combines the two logical statements into a boolean mask\n",
    "- We end up with patients who have started their treatment with CCRT, and who didn't get immunotherapy\n",
    "\n",
    "This reduces our original dataset quite a lot, now we only have 60 patients. After we've done some work here, maybe it would be a good idea to relax some of these requirements. You can choose how to relax them by changing the logical statements in this indexing."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "So now we have our cohort, selected based on their radiotherapy. We need to check a few other things are in order before we continue:\n",
    "\n",
    "- Do all the patients get the same overall dose?\n",
    "- Do all the patients get the same number of fractions?\n",
    "- Do we have all the outcome data we want to be able to do our datamining on these patients?\n",
    "\n",
    "The total dose recieved by the patient is in our database in the column \"RT Total Dose (Gy)\". We can go ahead and histogram this for the patients we have selected."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doses = ccrtOnlyPatients.hist(column=\"RT Total Dose (Gy)\", bins=20) ## you can adjust many bits of this plot!\n",
    "plt.xlabel(\"RT dose (Gy)\");\n",
    "plt.ylabel(\"# patients\");"
   ]
  },
  {
   "source": [
    "As you can see, most patients got a dose of 70 Gy, but there were a few who got higher or lower doses.\n",
    "\n",
    "Let's look at the dose per fraction next by indexing it to get a table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrtOnlyPatients[[\"Dose/Fraction (Gy/fx)\", \"RT Total Dose (Gy)\", \"Number of Fractions\"]]\n"
   ]
  },
  {
   "source": [
    "From this, we can see that all of the patients who got 72 Gy had a non-standard fractionation where they recieved some boost in the last couple of weeks of treatment. These patients always had their treatment in 40 fractions.\n",
    "\n",
    "For simplicity, we will exclude these patients. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedPatients = ccrtOnlyPatients[ccrtOnlyPatients[\"Number of Fractions\"].astype(int) < 40]\n",
    "len(selectedPatients[\"Number of Fractions\"])"
   ]
  },
  {
   "source": [
    "Now we have a nice clean dataset where all our patients got nice easy to manipulate fractionation, we need to adjust their doses to take account of the different doses per fraction.\n",
    "\n",
    "We have to do this because of how radiation works: 70 Gy in 33 fractions is a different biologically effective dose than 70 Gy in 35 fractions. If we don't adjust for this, then our results will probably not make any sense.\n",
    "\n",
    "Different fractionations have diferent effects because of the different amount of time normal tissue has to recover. Before we can mine data with different fractionations, we need to standardize somehow. This is usually done with a biologically equivalent dose (BED) calculation, or an equivalent dose @ 2 Gy/fraction (EQD2) calculation. Here we will do a simple BED calculation, whereby we just multiply the real dose by a factor to take account of the differences in fractionation.\n",
    "\n",
    "Also, whether we want to look at 'acute effects' (i.e. things that happen soon) or 'late effects' (i.e. things that happen after a few weeks/months) has a bearing on what we need to do here. The way these differences come into the BED calculation is in an $\\alpha/\\beta$ ratio. A ratio of $\\alpha/\\beta$ = 3.0 is usual when considering late effects.\n",
    "\n",
    "Now we have to choose an endpoint. Let's look at feeding tube insertion, which I think is probably an early effect. That means we need an $\\alpha/\\beta$ of 10."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function should create a voxelwise BED distribution. It makes the assumption that the dose in the plan is delivered in equal fractions\n",
    "## This is obviously not 100% true due to setup uncertainty, motion, etc, but it is an ok assumtion for now\n",
    "\n",
    "## BED = D_t * (1 + D_f/ab)  where:\n",
    "## D_t is the total dose (per voxel)\n",
    "## D_f = D_t/nFrac is the fraction dose per voxel\n",
    "## ab is the alpha/beta ratio\n",
    "\n",
    "def calculateVoxelwiseBED(dose, nFrac, alpha_beta=10.0):\n",
    "    factor = 1.0 / (nFrac*alpha_beta)\n",
    "\n",
    "    BED = dose*(1.0 + dose*factor)\n",
    "\n",
    "    return BED"
   ]
  },
  {
   "source": [
    "Now we have our BED correction, we can start loading data ready to do mining. We will load each image using SimpleITK, convert it to a numpy array and put it into a big numpy array. We will concurrently load the binary status from the clinical data as well and put that into a numpy array.\n",
    "\n",
    "In the next cell, we will load all our data. Note that we pre-allocate the numpy array we will use to hold the data - this is a performance optimisation to make loading the data a bit quicker."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dosesPath = \"/content/HNSCC_data/warpedDoses/\"\n",
    "availableDoses = [\"HNSCC-01-{0}\".format(a.split('.')[0]) for a in os.listdir(dosesPath)]\n",
    "\n",
    "availablePatientsMask = selectedPatients['ID'].isin(availableDoses)\n",
    "probeDose = sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(dosesPath, \"{0:04d}.nii\".format(int(2)))))\n",
    "\n",
    "availablePatients = selectedPatients.loc[availablePatientsMask]\n",
    "len(availablePatients)\n",
    "\n",
    "\n",
    "\n",
    "doseArray = np.zeros((len(availablePatients), *probeDose.shape))\n",
    "statusArray = np.zeros((len(availablePatients),))\n",
    "\n",
    "print(doseArray.shape)\n",
    "\n",
    "\n",
    "n = 0\n",
    "for idx, pt in availablePatients.iterrows():\n",
    "    dose_arr = sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(dosesPath, f\"{pt.ID.split('-')[-1]}.nii\" ) ) )\n",
    "    doseArray[n,...] = calculateVoxelwiseBED(dose_arr, pt[\"Number of Fractions\"], alpha_beta=10.0)\n",
    "    statusArray[n] = int(pt[\"Alive or Dead\"] == \"Dead\")\n",
    "    n += 1\n",
    "    "
   ]
  },
  {
   "source": [
    "Now we should have the dose and status data loaded, so we can start doing data mining!\n",
    "\n",
    "Here we will defien a function to do binary data mining using a Student t-Test approach. This involves calculating the mean and variance in every voxel for each status group, then using that on a per-voxel basis to caluclate the per-voxel value of t. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateT(doses, labels, mask=None):\n",
    "    \"\"\"\n",
    "    Use scipy t test calculation to get a t map for this set of doses and labels\n",
    "\n",
    "    Note, strictly we are doing welchs t test, which does not assume equal variance. Given this is per voxel, not assuming equal variance is the right thing to do\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        t_map, p_map = ttest_ind(doses[labels == 0], doses[labels == 1], axis=0, equal_var=False, nan_policy='omit')\n",
    "    else:\n",
    "        t_map, p_map = ttest_ind((doses*mask)[labels == 0], (doses*mask)[labels == 1], axis=0, equal_var=False, nan_policy='omit')\n",
    "\n",
    "    return t_map, p_map"
   ]
  },
  {
   "source": [
    "As you can see, we have abdicated the statistics to scipy, because it is probably less prone to error than writing our own t test.01_Registration.ipynb\n",
    "\n",
    "We can now use this function with the data we have loaded to get a map of t values, which tells us how the dose affects outcome in different regions of the anatomy."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = sitk.GetArrayFromImage(sitk.ReadImage(\"D:/Dropbox/Work/Transfer/ColabData/HNSCC_data/0002_mask.nii\")).astype(np.float32)\n",
    "\n",
    "## mask will be 0 or 1, only calculate where it is 1, so set 0 regions to nan and use nan policy from ttest_ind to ignore them\n",
    "mask[mask == 0] = np.nan\n",
    "print(statusArray.shape)\n",
    "tMap, pMap = calculateT(doseArray, statusArray, mask=mask)\n",
    "\n",
    "referenceAnatomy = sitk.GetArrayFromImage(sitk.ReadImage(\"D:/Dropbox/Work/Transfer/ColabData/HNSCC_data/downsampledCTs/0002.nii\"))\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "anatomy = plt.imshow(referenceAnatomy[::-1,64,...], cmap='Greys_r')\n",
    "tMapOverlay = plt.imshow(tMap[::-1,64,...], alpha=0.5)\n",
    "_ = plt.axis('off')"
   ]
  },
  {
   "source": [
    "Now you should have an image of the patient anatomy overlaid with a t-map indicating where dose is having an effect on outcome.\n",
    "\n",
    "This is cool, but it isn't the whole story! We need to assess the statistical significance of the values in the t-map. Because there are so many voxels in the image, we can't do this analytically. This is known as a multiple comparisons problem.\n",
    "\n",
    "The standard way to assess significance in image based data mining is to do a permutation test. In this, we randomly shuffle the labels used to calculate the t-map, and compare the resulting permuted t-map to the original. Anywhere where the 'true' t-map is always more extreme than the permuted t-map is a statistically significant region.\n",
    "\n",
    "Usually, we record a single 'summary statistic' from the permutations. Here we will use the simplest summary statistic possible: the most extreme value.\n",
    "\n",
    "We can write two functions to help us do a permutation test: one to calculate the t-map for a given permutation, and another to organise the information coming from the permutations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doPermutation(doseData, statuses, mask=None):\n",
    "    \"\"\"\n",
    "    Permute the statuses and return the maximum t value for this permutation\n",
    "    Inputs:\n",
    "        - doseData: the dose data, should be structured such that the number of patients in it is along the last axis\n",
    "        - statuses: the outcome labels. 1 indicates an event, 0 indicates no event. These will be permuted in this function to \n",
    "                    assess the null hypothesis of no dose interaction\n",
    "    Returns:\n",
    "        - (tMin, tMax): the extreme values of the whole t-value map for this permutation\n",
    "    \"\"\"\n",
    "    pstatuses = np.random.permutation(statuses)\n",
    "    permT = calculateT(doseData, pstatuses, mask=mask)\n",
    "    return (np.nanmin(permT), np.nanmax(permT))"
   ]
  },
  {
   "source": [
    "This function is pretty simple, it uses a numpy function to randomly permute the status labels, then re-calculates the t-map.\n",
    "\n",
    "The returned values from this function are the smallest and largest values. Usually these will be negative and positive respectively, indicating a different effect of the dose on outcome."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutationTest(doseData, statuses, nperm=1000, mask=None):\n",
    "    \"\"\"\n",
    "    Perform a permutation test to get the global p-value and t-thresholds\n",
    "    Inputs:\n",
    "        - doseData: the dose data, should be structured such that the number of patients in it is along the last axis\n",
    "        - statuses: the outcome labels. 1 indicates an event, 0 indicates no event.\n",
    "        - nperm: The number of permutations to calculate. Defaults to 1000 which is the minimum for reasonable accuracy\n",
    "    Returns:\n",
    "        - globalPNeg: the global significance of the test for negative t-values\n",
    "        - globalPPos: the global significance of the test for positive t-values\n",
    "        - tThreshNeg: the list of minT from all the permutations, use it to set a significance threshold.\n",
    "        - tThreshPos: the list of maxT from all the permutations, use it to set a significance threshold.\n",
    "    \"\"\"\n",
    "    tthresh = []\n",
    "    gtCount = 0\n",
    "    ltCount = 0\n",
    "    trueT = calculateT(doseData, statuses, mask=mask)\n",
    "    trueMaxT = np.nanmax(trueT)\n",
    "    trueMinT = np.nanmin(trueT)\n",
    "    if haveTQDM:\n",
    "        for perm in tqdm(range(nperm)):\n",
    "            tthresh.append(doPermutation(doseData, statuses, mask=mask))\n",
    "            if tthresh[-1][1] > trueMaxT:\n",
    "                gtCount += 1.0\n",
    "            if tthresh[-1][0] < trueMinT:\n",
    "                ltCount += 1.0\n",
    "    else:\n",
    "        for perm in range(nperm):\n",
    "            tthresh.append(doPermutation(doseData, statuses, mask=mask))\n",
    "            if tthresh[-1][1] > trueMaxT:\n",
    "                gtCount += 1.0\n",
    "            if tthresh[-1][0] < trueMinT:\n",
    "                ltCount += 1.0\n",
    "    \n",
    "    globalpPos = gtCount / float(nperm)\n",
    "    globalpNeg = ltCount / float(nperm)\n",
    "    print(gtCount, ltCount)\n",
    "    tthresh = np.array(tthresh)\n",
    "    return (globalpNeg, globalpPos, sorted(tthresh[:,0]), sorted(tthresh[:,1]))"
   ]
  },
  {
   "source": [
    "This function organises the data returned from the doPermutation function, and returns us some global summary statistics, as well as an ordered array of maximum and minimum t values from the permutations, that can be used to place significance thresholds on the t-map from the true status labels.\n",
    "\n",
    "The nperm argument to this function is important. It is the number of permutations we will perform - this impacts the minimum p-value we can see (1/nperm) but more importantly impacts the length of time the analysis takes to run. A standard number of permutations would be 1000, though this might take a while!\n",
    "\n",
    "Let's apply the permutation test to our data!\n",
    "\n",
    "*Warning: this cell will take a long time to run! About 6 minutes on my laptop. If you don't have tqdm for a progressbar, have faith that it is working!*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pNeg, pPos, threshNeg, threshPos = permutationTest(doseArray, statusArray, nperm=10, mask=mask)"
   ]
  },
  {
   "source": [
    "Now we have what we need to look for a dose sensitive region! To get an idea whether we have anything to look at, we can look at the global p-values. These are contained in the pNeg and pPos variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pNeg, pPos)\n"
   ]
  },
  {
   "source": [
    "The usual threshold for saying a result is statstically sgnificant is p=<0.05. Unfortunately, in my example analysis we don't seem to have a globally significant result. Everything below here won't really work properly because there is no significant result in this case, however let's do it anyway so you can see what to do when you mine something else later and get a significant result!\n",
    "\n",
    "---\n",
    "\n",
    "We also have our map of T values, and the associated permutation test distribution, so we can plot the regions of significance overlaid on the t-map and CT anatomy. To do this, we use matplotlib's imshow and contourf functions as below"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# First show the CT\n",
    "ctImg = ax.imshow(referenceAnatomy[:,64,:], cmap='Greys_r')\n",
    "\n",
    "# Now add the t-map with some transparency\n",
    "tmapImg = ax.imshow(tMap[:,64,:], alpha=0.3)\n",
    "\n",
    "plt.axis('off');\n",
    "\n",
    "neg_p005 = np.percentile(threshNeg, 0.05)\n",
    "neg_p010 = np.percentile(threshNeg, 0.10) ## Contour plot needs two levels, so we use p=0.05 & 0.10\n",
    "pos_p005 = np.percentile(threshPos, 0.95)\n",
    "pos_p010 = np.percentile(threshPos, 0.9)\n",
    "\n",
    "print(neg_p005)\n",
    "## Now do the contourplot at the 95% level for p=0.05\n",
    "pos_contourplot = plt.contourf(tMap[:,64,:], levels=[pos_p010, pos_p005], colors='r')\n",
    "neg_contourplot = plt.contourf(tMap[:,64,:], levels=[neg_p005, neg_p010], colors='g')"
   ]
  },
  {
   "source": [
    "Now we have a complete pipeline to do image based data mining!\n",
    "\n",
    "Now use this pipeline to try mining against some of the other outcomes in the clinical data, for example:\n",
    "\n",
    "- Local/regional failure\n",
    "- Feeding tube insertion\n",
    "- Weight loss\n",
    "- Skeletal muscle index reduction\n",
    "\n",
    "Have fun!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}